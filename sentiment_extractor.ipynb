{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.util import *\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import tqdm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_csv('data/general-news-lines.csv')\n",
    "df_NGO = pd.read_csv('data/general-ngo-lines.csv')\n",
    "df_IGO = pd.read_csv('data/general-igo-lines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(df, stopwordList= []):\n",
    "    # convert 'Content' to 'Snippet'\n",
    "    df.rename(columns={'Content': 'Snippet'}, inplace=True)\n",
    "\n",
    "    # Remove rows with NaN in 'Snippet' column\n",
    "    df = df.dropna(subset=['Snippet'])\n",
    "\n",
    "    # Convert 'Snippet' column to strings in case there are any non-string types (wordnet breaks otherwise)\n",
    "    df['Snippet'] = df['Snippet'].astype(str)\n",
    "\n",
    "    # Lowercase all words\n",
    "    df['Snippet'] = df['Snippet'].str.lower()\n",
    "\n",
    "    # Remove html/markdown tags like \\n etc\n",
    "    df['Snippet'] = df['Snippet'].str.replace(r'<[^>]*>', '')\n",
    "\n",
    "    # Remove punctuation\n",
    "    df['Snippet'] = df['Snippet'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "\n",
    "    # Remove special characters\n",
    "    df['Snippet'] = df['Snippet'].str.replace('[^A-Za-z ]+', '')\n",
    "\n",
    "    # Remove single characters\n",
    "    df['Snippet'] = df['Snippet'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Add excluded words to stopwords\n",
    "    stop_words.update(['said', 'would', 'also', 'could', 'year', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten'])\n",
    "    # Add custom stopwords\n",
    "    stop_words.update(stopwordList)\n",
    "\n",
    "    df['Snippet'] = df['Snippet'].apply(lambda x: ' '.join([item for item in x.split() if item.lower() not in stop_words]))\n",
    "\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['Snippet'] = df['Snippet'].apply(lambda x: ' '.join([lemmatizer.lemmatize(item) for item in x.split()]))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace(r'<[^>]*>', '')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace('[{}]'.format(string.punctuation), '')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace('[^A-Za-z ]+', '')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace(r'<[^>]*>', '')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace('[{}]'.format(string.punctuation), '')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace('[^A-Za-z ]+', '')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace(r'<[^>]*>', '')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace('[{}]'.format(string.punctuation), '')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace('[^A-Za-z ]+', '')\n",
      "C:\\Users\\jules\\AppData\\Local\\Temp\\ipykernel_14496\\3249369788.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Snippet'] = df['Snippet'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Source</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FT-2008-1.txt</td>\n",
       "      <td>financial timeslondon edcompanies uk tuesday j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FT-2008-1.txt</td>\n",
       "      <td>page pv crystalox solar capitalise climate cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FT-2008-1.txt</td>\n",
       "      <td>company biggest manufacturer silicon component...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FT-2008-1.txt</td>\n",
       "      <td>earnings interest tax excluding onetime cost l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FT-2008-1.txt</td>\n",
       "      <td>december</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Source  \\\n",
       "0           0  FT-2008-1.txt   \n",
       "1           1  FT-2008-1.txt   \n",
       "2           2  FT-2008-1.txt   \n",
       "3           3  FT-2008-1.txt   \n",
       "4           4  FT-2008-1.txt   \n",
       "\n",
       "                                             Snippet  \n",
       "0  financial timeslondon edcompanies uk tuesday j...  \n",
       "1  page pv crystalox solar capitalise climate cha...  \n",
       "2  company biggest manufacturer silicon component...  \n",
       "3  earnings interest tax excluding onetime cost l...  \n",
       "4                                           december  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = cleanData(df_news)\n",
    "df_NGO = cleanData(df_NGO)\n",
    "df_IGO = cleanData(df_IGO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure CUDA (GPU support) is available and enabled.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the tokenizer and model.\n",
    "model_name = \"SamLowe/roberta-base-go_emotions\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Model evaluation mode, dropout layers are disabled. Used when making predictions and using the pretrained model.\n",
    "# Pytorch assumes the model is in training mode by default.\n",
    "model.eval()\n",
    "\n",
    "def classify_emotion(snippet):\n",
    "    # Tokenize the batch of snippets.\n",
    "    inputs = tokenizer(snippet, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    \n",
    "    # Make predictions.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the predicted class index.\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    return predictions.cpu().numpy()\n",
    "\n",
    "def getSentiment(df, batch_size = 16):\n",
    "    # Process the snippets in batches.\n",
    "    batch_size = batch_size \n",
    "    sentiments = []\n",
    "\n",
    "    for i in tqdm(range(0, len(df['Snippet']), batch_size), desc=\"Classifying\"):\n",
    "        batch_snippets = df['Snippet'][i:i + batch_size].tolist()\n",
    "        batch_predictions = classify_emotion(batch_snippets)\n",
    "        sentiments.extend(batch_predictions)\n",
    "\n",
    "    # Assign the predictions to the DataFrame.\n",
    "    df['Sentiment'] = sentiments\n",
    "\n",
    "    return df\n",
    "\n",
    "# Get the sentiment\n",
    "df_news = getSentiment(df_news)\n",
    "df_NGO = getSentiment(df_NGO)\n",
    "df_IGO = getSentiment(df_IGO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
